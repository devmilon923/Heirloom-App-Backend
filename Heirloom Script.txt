import os
import json
import re
from pymongo import MongoClient
import uuid
from datetime import datetime, timedelta
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import openai
import ipywidgets as widgets
from IPython.display import display, clear_output, HTML
from google.colab import userdata
import time
import logging
import spacy
from nltk.corpus import wordnet
import nltk
import random
from cachetools import TTLCache
 
# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
 
# Download NLTK data
nltk.download('wordnet')
nltk.download('punkt')
from nltk.tokenize import word_tokenize
 
# Load spaCy model
nlp = spacy.load("en_core_web_sm")
 
# MongoDB Atlas setup
logger.info("Connecting to MongoDB Atlas")
client = MongoClient(
    "mongodb+srv://tamannabdcalling4:kfQTC9evfsxzIaFa@cluster0.fnawduk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0",
    tls=True,
    tlsAllowInvalidCertificates=True
)
db = client["user_bots"]
users_collection = db["users"]
conversations = db["conversations"]  # Single collection for all conversations
journal_collection = db["journal_entries"]
embeddings_collection = db["embeddings"]
personalities_collection = db["personalities"]
errors_collection = db["errors"]
saved_greetings = db["saved_greetings"]
 
# Ensure indexes for efficient querying
logger.info("Creating indexes for MongoDB collections")
conversations.create_index([("user_id", 1), ("timestamp", -1)])
conversations.create_index([("speaker_id", 1), ("target_id", 1), ("timestamp", -1)])
conversations.create_index([("content", "text")])
journal_collection.create_index([("user_id", 1), ("timestamp", -1)])
journal_collection.create_index([("content", "text")])
embeddings_collection.create_index([("item_id", 1), ("item_type", 1)])
personalities_collection.create_index([("user_id", 1)])
errors_collection.create_index([("timestamp", -1)])
saved_greetings.create_index([("target_id", 1), ("bot_role", 1), ("timestamp", -1)])
 
# Load sentence transformer for RAG retrieval
logger.info("Loading SentenceTransformer model")
retriever = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')
 
# OpenAI setup
OPENAI_API_KEY = userdata.get('OPENAI_API_KEY2')
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY2 not found in Colab userdata")
    raise ValueError("OPENAI_API_KEY2 not found in Colab userdata")
logger.info("OpenAI API key loaded successfully")
client2 = openai.OpenAI(api_key=OPENAI_API_KEY)
 
def list_available_models():
    logger.info("Listing available OpenAI models")
    try:
        models = client2.models.list()
        available_models = [model.id for model in models.data if 'gpt' in model.id.lower()]
        logger.info(f"Available models: {available_models}")
        return available_models
    except Exception as e:
        logger.error(f"Failed to list models: {str(e)}")
        return []
 
# Demo users with family relationships
demo_users = [
    {"user_id": "user1", "name": "Alice"},
    {"user_id": "user2", "name": "Bob"},
    {"user_id": "user3", "name": "Charlie"},
    {"user_id": "user4", "name": "Diana"}
]
 
# Demo conversations reflecting family dynamics
demo_conversations_list = [
    {
        "conversation_id": "conv1",
        "user_id": ["user1", "user3"],
        "speaker_id": "user1",
        "speaker_name": "Alice",
        "target_id": "user3",
        "target_name": "Charlie",
        "content": "Dad, the camping trip with you and Bob was so fun!",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2020, 5, 4, 8, 21, 35)
    },
    {
        "conversation_id": "conv2",
        "user_id": ["user1", "user4"],
        "speaker_id": "user1",
        "speaker_name": "Alice",
        "target_id": "user4",
        "target_name": "Diana",
        "content": "I'm thinking of studying abroad. Will you and Bob visit me?",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 6, 8, 21, 35)
    },
    {
        "conversation_id": "conv3",
        "user_id": ["user1", "user3"],
        "speaker_id": "user3",
        "speaker_name": "Charlie",
        "target_id": "user1",
        "target_name": "Alice",
        "content": "sure alice, you remember the trip?",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2020, 5, 11, 8, 23, 16)
    },
    {
        "conversation_id": "conv4",
        "user_id": ["user1", "user2"],
        "speaker_id": "user1",
        "speaker_name": "Alice",
        "target_id": "user2",
        "target_name": "Bob",
        "content": "Bob, can you help me with my homework tonight?",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 10, 17, 45, 0)
    },
    {
        "conversation_id": "conv5",
        "user_id": ["user2", "user1"],
        "speaker_id": "user2",
        "speaker_name": "Bob",
        "target_id": "user1",
        "target_name": "Alice",
        "content": "Of course, I can help you! What subject is it?",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 10, 17, 50, 0)
    },
    {
        "conversation_id": "conv6",
        "user_id": ["user1", "user2"],
        "speaker_id": "user1",
        "speaker_name": "Alice",
        "target_id": "user2",
        "target_name": "Bob",
        "content": "It's math, mostly algebra problems.",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 10, 18, 0, 0)
    },
    {
        "conversation_id": "conv7",
        "user_id": ["user2", "user1"],
        "speaker_id": "user2",
        "speaker_name": "Bob",
        "target_id": "user1",
        "target_name": "Alice",
        "content": "Got it, let me grab my notes. I'll be right there.",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 10, 18, 10, 0)
    },
    {
        "conversation_id": "conv8",
        "user_id": ["user3", "user4"],
        "speaker_id": "user3",
        "speaker_name": "Charlie",
        "target_id": "user4",
        "target_name": "Diana",
        "content": "I’m thinking of planning a family trip for the summer. What do you think?",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 11, 9, 30, 0)
    },
    {
        "conversation_id": "conv9",
        "user_id": ["user4", "user3"],
        "speaker_id": "user4",
        "speaker_name": "Diana",
        "target_id": "user3",
        "target_name": "Charlie",
        "content": "That sounds wonderful! I think it will be great for all of us.",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 11, 9, 35, 0)
    },
    {
        "conversation_id": "conv10",
        "user_id": ["user1", "user4"],
        "speaker_id": "user1",
        "speaker_name": "Alice",
        "target_id": "user4",
        "target_name": "Diana",
        "content": "Mom, do you want to go shopping this weekend?",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 12, 10, 15, 0)
    },
    {
        "conversation_id": "conv11",
        "user_id": ["user4", "user1"],
        "speaker_id": "user4",
        "speaker_name": "Diana",
        "target_id": "user1",
        "target_name": "Alice",
        "content": "I’d love to, Alice! Let’s go on Saturday morning.",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 12, 10, 20, 0)
    },
    {
        "conversation_id": "conv12",
        "user_id": ["user3", "user1"],
        "speaker_id": "user3",
        "speaker_name": "Charlie",
        "target_id": "user1",
        "target_name": "Alice",
        "content": "Alice, don’t forget to bring back a souvenir from your trip abroad!",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 12, 10, 30, 0)
    },
    {
        "conversation_id": "conv13",
        "user_id": ["user1", "user3"],
        "speaker_id": "user1",
        "speaker_name": "Alice",
        "target_id": "user3",
        "target_name": "Charlie",
        "content": "I’ll make sure to get something special for you, Dad!",
        "type": "user_input",
        "source": "human",
        "timestamp": datetime(2025, 5, 12, 10, 35, 0)
    }
]
 
# Demo journal entries reflecting family dynamics
demo_journals = {
    "user1": [
        {"entry_id": "journal1", "content": "Camping with Dad and Bob was the best. Love our family time.", "timestamp": datetime(2020, 5, 6, 9, 0, 0)},
        {"entry_id": "journal2", "content": "Studying abroad is exciting, but I’ll miss Bob’s dumb jokes.", "timestamp": datetime(2025, 5, 8, 9, 0, 0)},
        {"entry_id": "journal3", "content": "Aced my math exam, Bob’s a great study buddy!", "timestamp": datetime(2025, 5, 10, 9, 0, 0)}
    ],
    "user2": [
        {"entry_id": "journal4", "content": "Fixing the car with Dad was so cool. I want to be an engineer.", "timestamp": datetime(2020, 5, 5, 9, 0, 0)},
        {"entry_id": "journal5", "content": "Helped Alice with math. She’s smart, but my project’s stressing me out.", "timestamp": datetime(2025, 5, 7, 9, 0, 0)},
        {"entry_id": "journal6", "content": "Hiking with Mom sounds fun. Hope Alice comes!", "timestamp": datetime(2025, 5, 9, 9, 0, 0)}
    ],
    "user3": [
        {"entry_id": "journal7", "content": "Alice and Bob are growing up fast. So proud.", "timestamp": datetime(2020, 5, 4, 9, 0, 0)},
        {"entry_id": "journal8", "content": "Worried about Alice studying abroad, but she’s ready.", "timestamp": datetime(2025, 5, 8, 9, 0, 0)},
        {"entry_id": "journal9", "content": "Planning a family night. Love these moments with the kids.", "timestamp": datetime(2025, 5, 10, 9, 0, 0)}
    ],
    "user4": [
        {"entry_id": "journal10", "content": "So proud of Alice for acing her math exam. Baking cookies with her will be fun!", "timestamp": datetime(2025, 5, 9, 9, 0, 0)},
        {"entry_id": "journal11", "content": "Worried about Alice studying abroad. Need to discuss with Charlie.", "timestamp": datetime(2025, 5, 10, 9, 0, 0)}
    ]
}
 
def store_demo_data():
    logger.info("Starting store_demo_data")
    # Clear collections
    users_collection.delete_many({})
    conversations.delete_many({})
    journal_collection.delete_many({})
    embeddings_collection.delete_many({})
    personalities_collection.delete_many({})
    saved_greetings.delete_many({})
    db.greetings.delete_many({})
 
    # Insert users
    for user in demo_users:
        user_id = user["user_id"]
        logger.debug(f"Inserting user: {user_id}, name: {user['name']}")
        try:
            users_collection.update_one(
                {"user_id": user_id},
                {"$set": {"user_id": user_id, "name": user['name']}},
                upsert=True
            )
            logger.debug(f"Upserted user: {user_id}")
        except Exception as e:
            logger.error(f"Failed to upsert user {user_id}: {str(e)}")
            raise
 
    # Insert demo conversations and embeddings
    for conv in demo_conversations_list:
        try:
            required_fields = ["conversation_id", "user_id", "speaker_id", "speaker_name", "target_id", "target_name", "content", "type", "source", "timestamp"]
            if not all(field in conv for field in required_fields):
                logger.warning(f"Skipping invalid conversation {conv['conversation_id']}: missing fields {set(required_fields) - set(conv.keys())}")
                continue
            conversations.insert_one(conv)
            logger.debug(f"Inserted conversation: conv_id={conv['conversation_id']}, content='{conv['content'][:50]}...'")
 
            processed_content = preprocess_input(conv["content"])
            if not embeddings_collection.find_one({"item_id": conv["conversation_id"], "item_type": "conversation"}):
                embedding = retriever.encode(processed_content, normalize_embeddings=True).tolist()
                emb_doc = {
                    "item_id": conv["conversation_id"],
                    "item_type": "conversation",
                    "user_id": conv["user_id"],
                    "speaker_id": conv["speaker_id"],
                    "target_id": conv["target_id"],
                    "speaker_name": conv["speaker_name"],
                    "target_name": conv["target_name"],
                    "embedding": embedding,
                    "timestamp": conv["timestamp"]
                }
                embeddings_collection.insert_one(emb_doc)
                logger.debug(f"Stored conversation embedding: conv_id={conv['conversation_id']}")
        except Exception as e:
            logger.error(f"Failed to store conversation {conv['conversation_id']}: {str(e)}")
            continue
 
    # Insert journal entries and embeddings
    for user_id, entries in demo_journals.items():
        user = users_collection.find_one({"user_id": user_id})
        if not user:
            logger.error(f"User {user_id} not found for journal entries")
            continue
        speaker_name = user["name"]
        for entry in entries:
            try:
                required_fields = ["entry_id", "content", "timestamp"]
                if not all(field in entry for field in required_fields):
                    logger.warning(f"Skipping journal {entry['entry_id']}: missing fields {set(required_fields) - set(entry.keys())}")
                    continue
                journal_doc = {
                    "entry_id": entry["entry_id"],
                    "user_id": [user_id],
                    "speaker_id": user_id,
                    "speaker_name": speaker_name,
                    "content": entry["content"],
                    "timestamp": entry["timestamp"]
                }
                journal_collection.update_one(
                    {"entry_id": entry["entry_id"], "user_id": [user_id]},
                    {"$set": journal_doc},
                    upsert=True
                )
                logger.debug(f"Upserted journal: entry_id={entry['entry_id']}, user_id={user_id}, content='{entry['content'][:50]}...'")
 
                if not embeddings_collection.find_one({"item_id": entry["entry_id"], "item_type": "journal", "user_id": [user_id]}):
                    processed_content = preprocess_input(entry["content"])
                    embedding = retriever.encode(processed_content, normalize_embeddings=True).tolist()
                    emb_doc = {
                        "item_id": entry["entry_id"],
                        "item_type": "journal",
                        "user_id": [user_id],
                        "speaker_id": user_id,
                        "speaker_name": speaker_name,
                        "embedding": embedding,
                        "timestamp": entry["timestamp"]
                    }
                    embeddings_collection.insert_one(emb_doc)
                    logger.debug(f"Stored journal embedding: entry_id={entry['entry_id']}, user_id={user_id}")
            except Exception as e:
                logger.error(f"Failed to store journal {entry['entry_id']} for user {user_id}: {str(e)}")
                continue
 
    # Insert demo greetings (unchanged)
    demo_greetings = [
        {
            "greeting_id": str(uuid.uuid4()),
            "target_id": "user1",
            "user_id": "user4",
            "bot_role": "daughter",
            "greeting": "Hey, Mom",
            "timestamp": datetime(2025, 5, 9, 8, 31, 35)
        },
        {
            "greeting_id": str(uuid.uuid4()),
            "target_id": "user1",
            "user_id": "user3",
            "bot_role": "daughter",
            "greeting": "Hey, Dad",
            "timestamp": datetime(2025, 5, 11, 8, 23, 16)
        }
    ]
    for greeting in demo_greetings:
        try:
            saved_greetings.insert_one(greeting)
            logger.debug(f"Inserted greeting: {greeting['greeting']}")
        except Exception as e:
            logger.error(f"Failed to store greeting for target_id {greeting['target_id']}: {str(e)}")
 
    # Verify insertions
    logger.info(f"Users count: {users_collection.count_documents({})}")
    logger.info(f"Conversations count: {conversations.count_documents({})}")
    logger.info(f"Journal entries count: {journal_collection.count_documents({})}")
    logger.info(f"Embeddings count: {embeddings_collection.count_documents({})}")
    logger.info(f"Conversation embeddings: {embeddings_collection.count_documents({'item_type': 'conversation'})}")
    logger.info(f"Journal embeddings: {embeddings_collection.count_documents({'item_type': 'journal'})}")
    logger.info(f"Greetings count: {saved_greetings.count_documents({})}")
 
 
 
def get_recent_conversation_history(speaker_id, target_id, limit=6):
    logger.info(f"Retrieving recent conversation history for speaker={speaker_id}, target={target_id}, limit={limit}")
    history = []
    pipeline = [
        {
            "$match": {
                "user_id": {"$all": [speaker_id, target_id]},
                "$or": [
                    {"speaker_id": speaker_id, "target_id": target_id},
                    {"speaker_id": target_id, "target_id": speaker_id}
                ]
            }
        },
        {"$sort": {"timestamp": -1}},
        {"$limit": limit},
        {"$sort": {"timestamp": 1}}
    ]
    try:
        recent_convs = list(conversations.aggregate(pipeline))
        for conv in recent_convs:
            speaker_name = conv.get("speaker_name", users_collection.find_one({"user_id": conv["speaker_id"]})["name"])
            timestamp = conv["timestamp"].strftime("%Y-%m-%d %H:%M:%S")
            history.append({
                "speaker": speaker_name,
                "content": conv["content"],
                "timestamp": timestamp,
                "type": conv["type"],
                "source": conv.get("source", "human"),
                "raw_timestamp": conv["timestamp"],
                "conversation_id": conv["conversation_id"]
            })
            logger.debug(f"Added history entry: speaker={speaker_name}, content='{conv['content'][:50]}...', source={conv.get('source')}")
        logger.info(f"Retrieved {len(history)} history entries")
        return history
    except Exception as e:
        logger.error(f"Failed to retrieve conversation history: {str(e)}")
        return []
 
def generate_personality_traits(user_id):
    logger.info(f"Generating personality traits for user_id={user_id}")
    convs = list(conversations.find({"user_id": user_id}))
    journals = list(journal_collection.find({"user_id": user_id}))
    logger.debug(f"Found {len(convs)} conversations and {len(journals)} journal entries")
    data_text = "\n".join([c["content"] for c in convs] + [j["content"] for j in journals])[:1000]
 
    if not data_text:
        logger.warning(f"No data for user {user_id}")
        return {"core_traits": {}, "sub_traits": []}
 
    cached_traits = personalities_collection.find_one({"user_id": user_id})
    if cached_traits and "traits" in cached_traits:
        logger.info(f"Using cached traits for user {user_id}")
        return cached_traits["traits"]
 
    big_five_prompt = f"""
    Analyze this text from {users_collection.find_one({"user_id": user_id})["name"]}:
    {data_text}
 
    Return a JSON object with:
    - "core_traits": 5 traits (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) with scores (0-100) and one-sentence explanations.
    - "sub_traits": 3 unique traits with one-sentence descriptions.
    Ensure the response is concise to fit within 700 tokens.
    """
 
    for attempt in range(3):
        try:
            response = client2.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that generates personality traits based on user data."},
                    {"role": "user", "content": big_five_prompt}
                ],
                max_tokens=700,
                temperature=0.7
            )
            response_text = response.choices[0].message.content.strip()
            response_text = re.sub(r'^```json\s*|\s*```$', '', response_text, flags=re.MULTILINE).strip()
            traits = json.loads(response_text)
            if "core_traits" in traits and "sub_traits" in traits:
                if isinstance(traits["core_traits"], list):
                    traits["core_traits"] = {t["trait"]: {"score": t["score"], "explanation": t["explanation"]} for t in traits["core_traits"]}
                logger.info(f"Successfully generated traits for user {user_id}")
                break
        except Exception as e:
            logger.error(f"Trait generation attempt {attempt + 1} failed: {str(e)}")
            if attempt < 2:
                time.sleep(2 ** attempt)
            else:
                traits = {
                    "core_traits": {
                        "Openness": {"score": 50, "explanation": "Neutral openness based on limited data."},
                        "Conscientiousness": {"score": 50, "explanation": "Neutral conscientiousness."},
                        "Extraversion": {"score": 50, "explanation": "Neutral extraversion."},
                        " Agreeableness": {"score": 50, "explanation": "Neutral agreeableness."},
                        "Neuroticism": {"score": 50, "explanation": "Neutral neuroticism."}
                    },
                    "sub_traits": [
                        {"trait": "neutral", "description": "Shows balanced behavior."},
                        {"trait": "adaptable", "description": "Adapts to available context."},
                        {"trait": "curious", "description": "Engages with provided data."}
                    ]
                }
 
    personalities_collection.update_one(
        {"user_id": user_id},
        {"$set": {"traits": traits}},
        upsert=True
    )
    logger.info(f"Stored traits for user {user_id}")
    return traits
 
 
 
def get_greeting_and_tone(bot_role, target_id):
    logger.info(f"Generating greeting and tone for bot_role={bot_role}, target_id={target_id}")
    greeting_key = f"greeting_{target_id}_{bot_role}"
    cached_greeting = db.greetings.find_one({"key": greeting_key, "timestamp": {"$gte": datetime.utcnow() - timedelta(hours=1)}})
    if cached_greeting:
        return cached_greeting["greeting"], cached_greeting["tone"]
 
    saved_greeting = saved_greetings.find_one(
        {"target_id": target_id, "bot_role": bot_role.lower()},
        sort=[("timestamp", -1)]
    )
    if saved_greeting:
        logger.debug(f"Using saved greeting: {saved_greeting['greeting']}")
        return saved_greeting["greeting"], "warm, youthful" if bot_role.lower() in ["daughter", "son"] else "nurturing, caring"
 
    default_greetings = {
        "daughter": ("Hey, Mom", "warm, youthful"),
        "son": ("Hey, Mom", "warm, youthful"),
        "mother": ("Hi, sweetie", "nurturing, caring"),
        "father": ("Hey, kid", "warm, supportive"),
        "sister": ("Yo, sis", "playful, casual"),
        "brother": ("Yo, bro", "playful, casual"),
        "wife": ("Hey, love", "affectionate, conversational"),
        "husband": ("Hey, hon", "affectionate, conversational"),
        "friend": ("Hey, what's good?", "casual, friendly")
    }
    greeting, tone = default_greetings.get(bot_role.lower(), ("Hey", "casual, friendly"))
 
    traits = generate_personality_traits(target_id)
    prompt = f"""
    Generate a JSON object for a {bot_role} with traits: {', '.join([f"{k}" for k in traits['core_traits'].keys()])}.
    Return: {{"greeting": "short greeting (e.g., 'Hey, Mom')", "tone": "tone description (e.g., 'warm, youthful')"}}
    Ensure valid JSON.
    """
    for attempt in range(3):
        try:
            response = client2.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": "Return valid JSON."}, {"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.5
            )
            response_text = response.choices[0].message.content.strip()
            response_text = re.sub(r'^```json\s*|\s*```$', '', response_text, flags=re.MULTILINE).strip()
            result = json.loads(response_text)
            greeting, tone = result["greeting"], result["tone"]
            logger.debug(f"Generated greeting: {greeting}, tone: {tone}")
            break
        except Exception as e:
            logger.error(f"Greeting generation attempt {attempt + 1} failed: {str(e)}")
            if attempt < 2:
                time.sleep(2 ** attempt)
 
    db.greetings.update_one(
        {"key": greeting_key},
        {"$set": {"greeting": greeting, "tone": tone, "timestamp": datetime.utcnow()}},
        upsert=True
    )
    return greeting, tone
 
import spacy
import re
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
 
# Load spaCy and SentenceTransformer (already in your code)
nlp = spacy.load("en_core_web_sm")
retriever = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')
 
 
def initialize_bot(speaker_id, target_id, bot_role, user_input):
    logger.info(f"Initializing bot: speaker_id={speaker_id}, target_id={target_id}, bot_role={bot_role}, input='{user_input[:50]}...'")
    speaker = users_collection.find_one({"user_id": speaker_id})
    target = users_collection.find_one({"user_id": target_id})
    if not speaker or not target:
        logger.error(f"Invalid speaker or target: speaker={speaker}, target={target}")
        raise ValueError("Invalid speaker or target ID")
 
    traits = generate_personality_traits(target_id)
    recent_history = get_recent_conversation_history(speaker_id, target_id)
    history_text = "\n".join([f"{msg['speaker']}: {msg['content']}" for msg in recent_history]) or "No recent conversation history."
    logger.debug(f"Recent history: {history_text[:100]}...")
 
    use_greeting = not recent_history or (datetime.utcnow() - recent_history[-1]["raw_timestamp"]).total_seconds() / 60 > 30
    greeting, tone = get_greeting_and_tone(bot_role, target_id)
 
    # Check if memories should be included
    include_memories, memories = should_include_memories(user_input, speaker_id, target_id)
    memories_text = "No relevant memories."
    if include_memories and memories:
        try:
            valid_memories = [
                m for m in memories
                if all(key in m for key in ["content", "type", "timestamp", "speaker_name"])
            ]
            if valid_memories:
                memories_text = "\n".join([
                    f"- {m['content']} ({m['type']}, {m['timestamp'].strftime('%Y-%m-%d')}, said by {m['speaker_name']})"
                    for m in valid_memories
                ])
            else:
                logger.warning("No valid memories with required fields")
        except Exception as e:
            logger.error(f"Failed to format memories_text: {str(e)}")
            memories_text = "No relevant memories available."
 
    # Conditional prompt based on memory inclusion
    if include_memories:
        prompt = f"""
        You are {target['name']}, responding as an AI Twin to {speaker['name']}, you are their {bot_role}.
        Generate a short 2-3 sentence reply that:
        - Uses a {tone} tone, appropriate for your relationship with {speaker['name']}.
        - Reflects your personality: {', '.join([f"{k} ({v['explanation']})" for k, v in list(traits['core_traits'].items())[:3]])}.
        - Uses this recent conversation history for context:
        {history_text}
        - If relevant to '{user_input}', weave in one or two of these memories naturally, clearly attributing them to their speaker (e.g., 'Alice said...'):
        {memories_text}
        - Do not attribute memories from other users (e.g., Alice) to {speaker['name']}; reference them as belonging to their speaker.
        - Prioritize recent and highly relevant memories; avoid vague or unrelated references.
        - {'Starts with "' + greeting + '" if no recent messages or time gap > 30 minutes.' if use_greeting else 'Do not start with a greeting.'}
        - Keeps responses short, casual, and personalized.
        - Avoids incorrect relational terms (e.g., calling {speaker['name']} 'kiddo' if not a parent).
 
        Input: {user_input}
        """
    else:
        prompt = f"""
        You are {target['name']}, responding as an AI Twin to {speaker['name']}, you are their {bot_role}.
        Generate a short 2-3 sentence reply that:
        - Uses a {tone} tone, appropriate for your relationship with {speaker['name']}.
        - Reflects your personality: {', '.join([f"{k} ({v['explanation']})" for k, v in list(traits['core_traits'].items())[:3]])}.
        - Uses this recent conversation history for context:
        {history_text}
        - Focuses on the current input without referencing past memories unless explicitly relevant.
        - {'Starts with "' + greeting + '" if no recent messages or time gap > 30 minutes.' if use_greeting else 'Do not start with a greeting.'}
        - Keeps responses short, casual, and personalized.
        - Avoids incorrect relational terms (e.g., calling {speaker['name']} 'kiddo' if not a parent).
 
        Input: {user_input}
        """
 
    logger.info(f"Generated prompt for {target['name']}: {prompt[:200]}...")
    return prompt, greeting, use_greeting
 
 
 
embedding_cache = TTLCache(maxsize=1000, ttl=3600)
 
def preprocess_input(user_input):
    logger.debug(f"Preprocessing input: {user_input[:50]}...")
    try:
        doc = nlp(user_input)
        key_terms = [token.text.lower() for token in doc if token.pos_ in ["NOUN", "VERB"] and not token.is_stop]
        extra_terms = []
        for term in key_terms:
            synsets = wordnet.synsets(term)
            synonyms = set()
            for syn in synsets:
                for lemma in syn.lemmas():
                    synonym = lemma.name().replace('_', ' ')
                    if synonym != term and len(synonym.split()) <= 2:
                        synonyms.add(synonym)
                extra_terms.extend(list(synonyms)[:3])
        if extra_terms:
            user_input += " " + " ".join(set(extra_terms[:10]))
        return user_input
    except Exception as e:
        logger.error(f"Preprocessing failed: {str(e)}")
        return user_input
 
 
def find_relevant_memories(speaker_id, user_id, user_input, speaker_name, max_memories=5):
    logger.info(f"Finding memories: speaker={speaker_id}, user={user_id}, input='{user_input[:50]}...'")
    start_time = time.time()
 
    # Get recent history
    recent_history = get_recent_conversation_history(speaker_id, user_id)
    history_text = " ".join([msg["content"] for msg in recent_history])
    combined_input = f"{user_input} {history_text}" if history_text else user_input
    processed_input = preprocess_input(combined_input)
 
    # Generate input embedding
    cache_key = f"input_{hash(processed_input)}"
    if cache_key in embedding_cache:
        input_embedding = embedding_cache[cache_key]
    else:
        input_embedding = retriever.encode(processed_input, normalize_embeddings=True).reshape(1, -1)
        embedding_cache[cache_key] = input_embedding
 
    memories = []
    target_name = users_collection.find_one({"user_id": user_id})["name"]
 
    # Query embeddings for relevant users only
    embeddings = list(embeddings_collection.find({
        "item_type": {"$in": ["conversation", "journal"]},
        "user_id": {"$in": [[speaker_id, user_id], [user_id, speaker_id], [speaker_id], [user_id]]}
    }))
    logger.info(f"Found {len(embeddings)} embeddings")
 
    if not embeddings:
        logger.warning(f"No embeddings for user_id={user_id}")
        return []
 
    item_ids = []
    item_types = []
    emb_vectors = []
    emb_users = []
    emb_speakers = []
    emb_targets = []
    emb_speaker_names = []
    emb_target_names = []
 
    for emb in embeddings:
        try:
            item_ids.append(emb["item_id"])
            item_types.append(emb["item_type"])
            emb_vectors.append(emb["embedding"])
            emb_users.append(emb["user_id"])
            emb_speakers.append(emb.get("speaker_id", emb["user_id"][0] if emb["item_type"] == "journal" else None))
            emb_targets.append(emb.get("target_id", None))
            emb_speaker_names.append(emb.get("speaker_name", users_collection.find_one({"user_id": emb_speakers[-1]})["name"]))
            emb_target_names.append(emb.get("target_name", users_collection.find_one({"user_id": emb_targets[-1]})["name"] if emb_targets[-1] else None))
        except (KeyError, TypeError) as e:
            logger.warning(f"Skipping invalid embedding: {str(e)}")
            continue
 
    if emb_vectors:
        emb_vectors = np.array(emb_vectors)
        similarities = cosine_similarity(input_embedding, emb_vectors)[0]
        logger.debug(f"Similarity stats: min={similarities.min():.3f}, max={similarities.max():.3f}")
 
        for idx, item_id in enumerate(item_ids):
            # Boost similarity for relevant users
            if emb_speakers[idx] == user_id or emb_targets[idx] == user_id:
                similarities[idx] += 0.5
                logger.debug(f"Boosted similarity for item {item_id} (user_id={user_id})")
            if speaker_name.lower() in item_ids[idx].lower() or target_name.lower() in item_ids[idx].lower():
                similarities[idx] += 0.2
            days_old = (datetime.utcnow() - embeddings[idx]["timestamp"]).days
            temporal_weight = 1 / (1 + np.log1p(max(days_old, 1) / 365))
            similarities[idx] *= temporal_weight
 
        min_similarity = 0.4
        sorted_indices = np.argsort(similarities)[::-1]
        valid_indices = [i for i in sorted_indices if similarities[i] >= min_similarity][:max_memories]
 
        for idx in valid_indices:
            item_id = item_ids[idx]
            item_type = item_types[idx]
            collection = conversations if item_type == "conversation" else journal_collection
            # Fix query: Use 'entry_id' for journals, 'conversation_id' for conversations
            id_field = "conversation_id" if item_type == "conversation" else "entry_id"
            query = {id_field: item_id, "user_id": emb_users[idx]}
            doc = collection.find_one(query)
            if not doc:
                logger.warning(f"No document for item_id={item_id}, type={item_type}, query={query}")
                continue
            required_fields = ["content", "timestamp", "speaker_name"]
            if not all(f in doc for f in required_fields):
                logger.warning(f"Skipping memory {item_id}: missing fields")
                continue
            memory = {
                "type": item_type,
                "content": doc["content"],
                "timestamp": doc["timestamp"],
                "score": float(similarities[idx]),
                "user_id": emb_users[idx],
                "speaker_id": emb_speakers[idx],
                "speaker_name": emb_speaker_names[idx],
                "target_id": emb_targets[idx],
                "target_name": emb_target_names[idx]
            }
            memories.append(memory)
            logger.debug(f"Added memory: {memory['content'][:50]}..., score={similarities[idx]:.3f}")
 
    # Semantic text search fallback
    if len(memories) < max_memories:
        logger.info(f"Fallback semantic search for {max_memories - len(memories)} memories")
        for collection in [conversations, journal_collection]:
            item_type = "conversation" if collection == conversations else "journal"
            id_field = "conversation_id" if item_type == "conversation" else "entry_id"
            text_matches = collection.find({
                "user_id": {"$in": [[speaker_id, user_id], [user_id, speaker_id], [speaker_id], [user_id]]},
                "$or": [{"speaker_id": user_id}, {"target_id": user_id}]
            }).limit(max_memories - len(memories))
            for match in text_matches:
                match_embedding = retriever.encode(match["content"], normalize_embeddings=True)
                similarity = cosine_similarity(input_embedding, match_embedding.reshape(1, -1))[0][0]
                if similarity < 0.4:
                    continue
                speaker_id_in_match = match.get("speaker_id", match["user_id"][0] if collection == journal_collection else None)
                speaker_name_in_match = match.get("speaker_name", users_collection.find_one({"user_id": speaker_id_in_match})["name"])
                target_id_in_match = match.get("target_id", None)
                target_name_in_match = match.get("target_name", users_collection.find_one({"user_id": target_id_in_match})["name"] if target_id_in_match else None)
                required_fields = ["content", "timestamp", "speaker_name"]
                if not all(f in match for f in required_fields):
                    continue
                memory = {
                    "type": item_type,
                    "content": match["content"],
                    "timestamp": match["timestamp"],
                    "score": float(similarity),
                    "user_id": match["user_id"],
                    "speaker_id": speaker_id_in_match,
                    "speaker_name": speaker_name_in_match,
                    "target_id": target_id_in_match,
                    "target_name": target_name_in_match
                }
                memories.append(memory)
                logger.debug(f"Added semantic memory: {match['content'][:50]}...")
 
    memories = sorted(memories, key=lambda x: x["score"], reverse=True)[:max_memories]
    logger.info(f"Retrieved {len(memories)} memories in {time.time() - start_time:.2f}s")
    return memories
 
def should_include_memories(user_input, speaker_id, user_id):
    logger.info(f"Checking memory inclusion for input='{user_input[:50]}...'")
    start_time = time.time()
 
    doc = nlp(user_input.lower())
    input_tokens = {token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct}
 
    # Get memories
    memories = find_relevant_memories(speaker_id, user_id, user_input,
        users_collection.find_one({"user_id": speaker_id})["name"], max_memories=10)
 
    # Cache embeddings
    for m in memories:
        content_key = f"memory_{hash(m['content'][:100])}"
        if content_key not in embedding_cache:
            embedding_cache[content_key] = retriever.encode(m["content"], normalize_embeddings=True)
        m["embedding"] = embedding_cache[content_key]
 
    # Semantic similarity check
    relevant_memories = []
    if memories:
        try:
            input_embedding = retriever.encode(user_input, normalize_embeddings=True).reshape(1, -1)
            memory_embeddings = np.array([m["embedding"] for m in memories])
            similarities = cosine_similarity(input_embedding, memory_embeddings)[0]
            for i, m in enumerate(memories):
                if similarities[i] >= 0.5:
                    relevant_memories.append(m)
                    logger.debug(f"Included memory: {m['content'][:50]}..., score={similarities[i]:.3f}")
            logger.debug(f"Relevant memories: {len(relevant_memories)}")
        except Exception as e:
            logger.error(f"Similarity check failed: {str(e)}")
 
    logger.info(f"Memory check completed in {time.time() - start_time:.2f}s")
    return bool(relevant_memories), relevant_memories[:3]
 
def interact_with_bot(speaker_id, target_id, bot_role, user_input):
    logger.info(f"Interacting: speaker={speaker_id}, target={target_id}, role={bot_role}, input='{user_input[:50]}...'")
    start_time = time.time()
    try:
        speaker = users_collection.find_one({"user_id": speaker_id})
        target = users_collection.find_one({"user_id": target_id})
        if not speaker or not target:
            raise ValueError("Invalid speaker or target ID")
 
        # Store user input
        processed_input = preprocess_input(user_input)
        user_conv_id = str(uuid.uuid4())
        conv_doc = {
            "conversation_id": user_conv_id,
            "user_id": [speaker_id, target_id],
            "speaker_id": speaker_id,
            "speaker_name": speaker["name"],
            "target_id": target_id,
            "target_name": target["name"],
            "content": user_input,
            "type": "user_input",
            "source": "human",
            "timestamp": datetime.utcnow()
        }
        conversations.insert_one(conv_doc)
        embedding = retriever.encode(processed_input, normalize_embeddings=True).tolist()
        embeddings_collection.insert_one({
            "item_id": user_conv_id,
            "item_type": "conversation",
            "user_id": [speaker_id, target_id],
            "speaker_id": speaker_id,
            "target_id": target_id,
            "speaker_name": speaker["name"],
            "target_name": target["name"],
            "embedding": embedding,
            "timestamp": datetime.utcnow()
        })
 
        # Generate response
        respond_as_human = random.random() < 0.3
        if respond_as_human:
            response_text = simulate_human_response(speaker_id, target_id, user_input)
            response_source = "human"
        else:
            prompt, greeting, use_greeting = initialize_bot(speaker_id, target_id, bot_role, user_input)
            response_text = generate_response(prompt, user_input, greeting, use_greeting)
            response_source = "ai_twin"
 
        # Store response
        bot_conv_id = str(uuid.uuid4())
        processed_response = preprocess_input(response_text)
        conv_doc = {
            "conversation_id": bot_conv_id,
            "user_id": [speaker_id, target_id],
            "speaker_id": target_id,
            "speaker_name": target["name"],
            "target_id": speaker_id,
            "target_name": speaker["name"],
            "content": response_text,
            "type": "response",
            "source": response_source,
            "timestamp": datetime.utcnow()
        }
        conversations.insert_one(conv_doc)
        embedding = retriever.encode(processed_response, normalize_embeddings=True).tolist()
        embeddings_collection.insert_one({
            "item_id": bot_conv_id,
            "item_type": "conversation",
            "user_id": [speaker_id, target_id],
            "speaker_id": target_id,
            "target_id": speaker_id,
            "speaker_name": target["name"],
            "target_name": speaker["name"],
            "embedding": embedding,
            "timestamp": datetime.utcnow()
        })
 
        if response_source == "ai_twin" and response_text.lower().startswith(greeting.lower()) and use_greeting:
            negative_keywords = ["sorry", "ugh", "not again", "hate", "annoyed", "bad"]
            if not any(keyword in response_text.lower() for keyword in negative_keywords):
                saved_greetings.insert_one({
                    "greeting_id": str(uuid.uuid4()),
                    "target_id": target_id,
                    "user_id": speaker_id,
                    "bot_role": bot_role.lower(),
                    "greeting": greeting,
                    "timestamp": datetime.utcnow()
                })
 
        logger.info(f"Interaction completed in {time.time() - start_time:.2f}s")
        return response_text, None
    except Exception as e:
        logger.error(f"Interaction failed: {str(e)}")
        errors_collection.insert_one({"error": str(e), "input": user_input, "timestamp": datetime.utcnow()})
        return None, f"Error: {str(e)}"
 
 
 
def is_valid_response(response_text, greeting, use_greeting):
    logger.info(f"Validating response: {response_text[:50]}...")
    if not response_text or len(response_text.split()) < 4:
        logger.warning("Response invalid: too short or empty")
        return False
    if use_greeting and not response_text.lower().startswith(greeting.lower()):
        logger.warning(f"Response invalid: expected to start with '{greeting}'")
        return False
    if not use_greeting and response_text.lower().startswith(greeting.lower()):
        logger.warning(f"Response invalid: should not start with '{greeting}'")
        return False
    logger.info("Response valid")
    return True
 
def generate_response(prompt, user_input, greeting, use_greeting):
    logger.info(f"Generating response for input='{user_input[:50]}...'")
    try:
        response = client2.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an AI Twin responding in a personalized, casual manner."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.7
        )
        response_text = response.choices[0].message.content.strip()
        if is_valid_response(response_text, greeting, use_greeting):
            sentences = response_text.split('. ')[:3]
            response_text = '. '.join([s for s in sentences if s]).strip()
            if response_text and not response_text.endswith('.'):
                response_text += '.'
            if use_greeting and not response_text.lower().startswith(greeting.lower()):
                response_text = f"{greeting}, {response_text[0].lower()}{response_text[1:]}"
            logger.info(f"Valid response: {response_text[:50]}...")
            return response_text
        logger.warning(f"Invalid response: {response_text}")
    except Exception as e:
        logger.error(f"OpenAI failed: {str(e)}")
        errors_collection.insert_one({"error": str(e), "input": user_input, "timestamp": datetime.utcnow()})
 
    logger.info("Using fallback response")
    memories = find_relevant_memories(speaker_id, user_id, user_input, "user")
    top_memory = memories[0]["content"] if memories else "our past chats"
    prefix = f"{greeting}, " if use_greeting else ""
    return f"{prefix}sounds cool! Reminds me of {top_memory.lower()}. What's up?"
 
def simulate_human_response(speaker_id, target_id, user_input):
    logger.info(f"Simulating human response for speaker={speaker_id}, target={target_id}, input='{user_input[:50]}...'")
    relevant_convs = list(conversations.find({
        "speaker_id": target_id,
        "target_id": speaker_id,
        "$text": {"$search": user_input}
    }).sort("timestamp", -1).limit(1))
 
    if relevant_convs:
        response = relevant_convs[0]["content"]
        logger.debug(f"Using conversation response: {response}")
        return response
 
    traits = generate_personality_traits(target_id)
    prompt = f"""
    You are {users_collection.find_one({"user_id": target_id})["name"]}, responding to {users_collection.find_one({"user_id": speaker_id})["name"]}.
    Generate a short 1-2 sentence reply to '{user_input}' in a casual, friendly tone.
    Reflect these traits: {', '.join([f"{k}" for k in traits['core_traits'].keys()])}.
    """
    try:
        response = client2.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a human-like conversationalist."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.7
        )
        response_text = response.choices[0].message.content.strip()
        logger.debug(f"Generated human-like response: {response_text}")
        return response_text
    except Exception as e:
        logger.error(f"Failed to simulate human response: {str(e)}")
        return f"Hey, that sounds cool! What's next?"
 
 
def create_chat_interface():
    logger.info("Creating chat interface")
    user_dropdown = widgets.Dropdown(
        options=[(user["name"], user["user_id"]) for user in demo_users],
        description="Speaking As:",
        style={'description_width': 'initial'}
    )
    target_dropdown = widgets.Dropdown(
        options=[(user["name"], user["user_id"]) for user in demo_users],
        description="Talk to:",
        style={'description_width': 'initial'}
    )
    role_dropdown = widgets.Dropdown(
        options=["daughter", "son", "mother", "father", "sister", "brother", "friend", "husband", "wife"],
        description="Bot Role:",
        style={'description_width': 'initial'}
    )
    input_box = widgets.Textarea(
        value='',
        placeholder='Type your message here...',
        description='Input:',
        layout={'width': '500px', 'height': '100px'},
        style={'description_width': 'initial'}
    )
    output_area = widgets.Output()
    send_button = widgets.Button(description="Send")
 
    chatbox_css = """
    <style>
        .chat-container {
            width: 500px;
            height: 400px;
            overflow-y: scroll;
            border: 1px solid #ccc;
            padding: 10px;
            background-color: #f9f9f9;
            margin-bottom: 10px;
        }
        .message {
            margin: 5px 0;
            padding: 10px;
            border-radius: 10px;
            max-width: 80%;
            word-wrap: break-word;
        }
        .user-message {
            background-color: #007bff;
            color: white;
            margin-left: auto;
            text-align: right;
        }
        .response-message {
            background-color: #e9ecef;
            color: black;
            margin-right: auto;
            text-align: left;
        }
        .error-message {
            background-color: #f8d7da;
            color: #721c24;
            margin-right: auto;
            text-align: left;
        }
        .timestamp {
            font-size: 0.8em;
            color: #666;
            margin-top: 2px;
        }
    </style>
    """
    display(HTML(chatbox_css))
 
    def render_chatbox(speaker_id, target_id, bot_role, error_message=None):
        logger.info(f"Rendering chatbox for speaker={speaker_id}, target={target_id}, bot_role={bot_role}")
        with output_area:
            clear_output()
            speaker_name = users_collection.find_one({"user_id": speaker_id})["name"]
            target_name = users_collection.find_one({"user_id": target_id})["name"]
            recent_history = get_recent_conversation_history(speaker_id, target_id)
 
            chat_html = '<div class="chat-container">'
            if not recent_history and not error_message:
                chat_html += '<div style="text-align: center; color: #666;">No recent messages found.</div>'
            else:
                for msg in recent_history:
                    message_class = "user-message" if msg["type"] == "user_input" else "response-message"
                    sender = speaker_name if msg["type"] == "user_input" else target_name
                    chat_html += f'''
                        <div class="message {message_class}">
                            <strong>{sender}:</strong> {msg["content"]}
                            <div class="timestamp">{msg["timestamp"]}</div>
                        </div>
                    '''
                if error_message:
                    chat_html += f'''
                        <div class="message error-message">
                            <strong>Error:</strong> {error_message}
                            <div class="timestamp">{datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")}</div>
                        </div>
                    '''
            chat_html += '</div>'
            display(HTML(chat_html))
 
    def on_send_button_clicked(b):
        speaker_id = user_dropdown.value
        target_id = target_dropdown.value
        bot_role = role_dropdown.value
        user_input = input_box.value.strip()
        logger.info(f"Send button clicked: speaker={speaker_id}, target={target_id}, bot_role={bot_role}, input='{user_input[:50]}...'")
        if user_input:
            response, error = interact_with_bot(speaker_id, target_id, bot_role, user_input)
            render_chatbox(speaker_id, target_id, bot_role, error)
            input_box.value = ''
        else:
            render_chatbox(speaker_id, target_id, bot_role)
 
    send_button.on_click(on_send_button_clicked)
 
    def on_dropdown_change(change):
        render_chatbox(user_dropdown.value, target_dropdown.value, role_dropdown.value)
 
    user_dropdown.observe(on_dropdown_change, names='value')
    target_dropdown.observe(on_dropdown_change, names='value')
    role_dropdown.observe(on_dropdown_change, names='value')
 
    display(user_dropdown, target_dropdown, role_dropdown, input_box, send_button, output_area)
    render_chatbox(user_dropdown.value, target_dropdown.value, role_dropdown.value)
 
# Initialize demo data and embeddings
logger.info("Initializing demo data")
store_demo_data()
 
 
# Start chat interface
logger.info("Starting chat interface")
print("Starting chat interface...")
create_chat_interface()